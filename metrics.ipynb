{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from dicompylercore import dicomparser\n",
    "import cv2\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportional_resize(image, max_side):\n",
    "    if image.shape[0] > max_side or image.shape[1] > max_side:\n",
    "        if image.shape[0] > image.shape[1]:\n",
    "            height = max_side\n",
    "            width = int(height / image.shape[0] * image.shape[1])\n",
    "        else:\n",
    "            width = max_side\n",
    "            height = int(width / image.shape[1] * image.shape[0])\n",
    "    else:\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "    return cv2.resize(image, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new = true - read dicom, new = false - read png\n",
    "def prepare_dataset(path, new):\n",
    "    d_set = []\n",
    "    labels = []\n",
    "    folder = path.split(os.sep)[-1]\n",
    "    if new:\n",
    "        for path, directories, files in os.walk(path):\n",
    "            files = [file for file in files if not file[0] == \".\"]\n",
    "            for file in files:\n",
    "                f, extension = os.path.splitext(file)\n",
    "                label = path.split(os.sep)[-1]\n",
    "                if extension == \".dcm\":\n",
    "                    parsed = dicomparser.DicomParser(path + os.sep + file)\n",
    "                    print(file)\n",
    "                    image = np.array(parsed.GetImage(), dtype=np.uint8)\n",
    "                    if parsed.GetImageData()[\"photometricinterpretation\"] == \"MONOCHROME1\":\n",
    "                        image = 255 - image\n",
    "                    image = cv2.equalizeHist(image)\n",
    "                    image = cv2.medianBlur(image, 3)\n",
    "                    scaled_image = proportional_resize(image, 512)\n",
    "                    lungs_image = lf.get_lungs(scaled_image, 7)\n",
    "                    cv2.imwrite(\"lungs-set\" + os.sep + folder + os.sep + label + os.sep + f + \".png\", lungs_image)\n",
    "                    lungs_image = cv2.resize(lungs_image, (128, 128))\n",
    "                    if label == \"norm\":\n",
    "                        d_set.append(lungs_image)\n",
    "                        labels.append(1)\n",
    "                    elif label == \"pathology\":\n",
    "                        d_set.append(lungs_image)\n",
    "                        labels.append(0)\n",
    "                    else:\n",
    "                        continue\n",
    "    else:\n",
    "        path = \"lungs-set\" + os.sep + folder\n",
    "        for path, directories, files in os.walk(path):\n",
    "            files = [file for file in files if not file[0] == \".\"]\n",
    "            for file in files:\n",
    "                _, extension = os.path.splitext(file)\n",
    "                label = path.split(os.sep)[-1]\n",
    "                parsed = cv2.imread(path + os.sep + file, 0)\n",
    "                image = np.array(parsed, dtype=np.uint8)\n",
    "                lungs_image = cv2.resize(image, (256, 256))\n",
    "                if label == \"norm\":\n",
    "                    d_set.append(lungs_image)\n",
    "                    labels.append(1)\n",
    "                elif label == \"pathology\":\n",
    "                    d_set.append(lungs_image)\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    continue\n",
    "    return np.array(d_set), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downloading the dataset\n",
    "np.random.seed(42)\n",
    "def_width = 256\n",
    "def_height = 256\n",
    "train = \"/Volumes/DATA/KAMI/lung_dataset/train\"\n",
    "test = \"/Volumes/DATA/KAMI/lung_dataset/test\"\n",
    "x_train, y_train = prepare_dataset(train, False)\n",
    "x_test, y_test = prepare_dataset(test, False)\n",
    "# optional to shuffle the dataset\n",
    "#x_train, y_train = shuffle(x_train, y_train, random_state=0)\n",
    "#x_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "x_train = x_train.astype(dtype=\"float32\")\n",
    "x_test = x_test.astype(dtype=\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = x_train.reshape(x_train.shape[0], def_width, def_height, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], def_width, def_height, 1)\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 70.50%\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_256.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"weights_256.h5\")\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "score = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_base_metrics(predictions, y_test):\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    cond_pos = 0\n",
    "    cond_neg = 0\n",
    "    for idx, item in enumerate(predictions):\n",
    "        if(round(item[0])==0 and y_test[idx][0]==0):\n",
    "            tn+=1\n",
    "        elif (round(item[0])==0 and y_test[idx][0]==1):\n",
    "            fn+=1\n",
    "        elif (round(item[0])==1 and y_test[idx][0]==0):\n",
    "            fp+=1\n",
    "        else:\n",
    "            tp+=1\n",
    "        if (y_test[idx][0]==0):\n",
    "            cond_neg+=1\n",
    "        else:\n",
    "            cond_pos+=1\n",
    "    return (tp,tn,fp,fn,cond_pos,cond_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_metrics(tp,tn,fp,fn,cond_pos,cond_neg):\n",
    "    TPR = tp/cond_pos\n",
    "    TNR = tn/cond_neg\n",
    "    FPR = fp/cond_neg\n",
    "    FNR = fn/cond_pos\n",
    "    return(TPR,TNR,FPR,FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tp,tn,fp,fn,cond_pos,cond_neg) = count_base_metrics(predictions,y_test)\n",
    "(TPR,TNR,FPR,FNR) = count_metrics(tp,tn,fp,fn,cond_pos,cond_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:  0.875\n",
      "True Negative Rate:  0.5327510917030568\n",
      "False Positive Rate:  0.4672489082969432\n",
      "False Negative Rate:  0.125\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate: \",TPR)\n",
    "print(\"True Negative Rate: \",TNR)\n",
    "print(\"False Positive Rate: \",FPR)\n",
    "print(\"False Negative Rate: \",FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
